model_params:
  emb_word_size: 300
  emb_char_size: 200
  v_size: 128
  h_size: 150
  model_dim: 100
  num_layers: 3
  attn_type: additive
  pretrained_char: False

launch_params:
  learning_rate: 0.001
  num_steps: 60000
  batch_size: 16
  test_interval: 150
  train_interval: 10
  train_sample_interval: 150
  log: logs
  prefix: RNet_new
  lr_warm_up_num: 1000
  test_num_batches: 50
  val_num_batches: 50
  word_emb_file: target_dir/word_emb.json
  char_emb_file: target_dir/char_emb.json
  train_eval_file: target_dir/train_eval.json
  dev_eval_file: target_dir/dev_eval.json
  train_record_file: target_dir/train.npz
  dev_record_file: target_dir/dev.npz
  word2ind_file: target_dir/word2idx.json
  ema_decay: 0.9999
  beta1: 0.8
  beta2: 0.999
  lr_warm_up_num: 1000
